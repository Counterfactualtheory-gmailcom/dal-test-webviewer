<!doctype html>
<html lang="en">
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JR7LJGK5PK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-JR7LJGK5PK');
</script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>COMPAiSS</title>

  <style>
    :root{
      --wrap: 980px;
      --pad: 32px;

      --bg-page: #0c2d5a;
      --bg-panel: #10386e;
      --bg-panel-soft: rgba(16,56,110,0.55);

      --text-main: #c6cfdd;
      --text-muted: #aeb9cc;
      --text-heading: #ffffff;

      --accent: #f0c44c;
      --border-soft: rgba(255,255,255,0.08);

      --link: #9cc9ff;
      --link-visited: #c8e0ff;

      --radius: 10px;
    }

/* -------------------------------
   Section heading highlight ONLY
-------------------------------- */

#out h2{
  display: inline-block;
  background: rgba(255,255,255,0.08);
  padding: 0.35rem 0.7rem;
  border-radius: 6px;
  margin: 1.6rem 0 0.8rem -0.4rem; /* tighter */
}

/* Reduce gap between heading and first content line */
#out h2 + p,
#out h2 + ul{
  margin-top: 0.4rem;
}
    
    html,body{
      margin:0;
      padding:0;
      background:var(--bg-page);
      color:var(--text-main);
      font:18px/1.65 system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;
      -webkit-text-size-adjust:100%;
    }

#out img{
  max-width: 100%;
  height: auto;
  display: block;
  margin: 2.5rem auto;
  border-radius: 8px;
}
    
    a{
      color:var(--link);
      text-decoration:underline;
      text-underline-offset:0.15em;
    }
    a:visited{color:var(--link-visited)}
    a:hover,a:focus{opacity:.95}

    :focus-visible{
      outline:2px solid var(--accent);
      outline-offset:3px;
    }

    .skip-link{
      position:absolute;
      left:-999px;
      top:auto;
      width:1px;
      height:1px;
      overflow:hidden;
    }
    .skip-link:focus{
      left:16px;
      top:16px;
      width:auto;
      height:auto;
      background:#000;
      color:#fff;
      padding:8px 12px;
      z-index:1000;
    }

    header{
      border-bottom:1px solid var(--border-soft);
    }

    .nav{
      max-width:var(--wrap);
      margin:0 auto;
      padding:18px var(--pad);
      display:flex;
      align-items:center;
      justify-content:space-between;
    }

    .nav .brand-text{
      font-weight:600;
      letter-spacing:0.04em;
      color:var(--text-heading);
    }

    .nav ul{
      list-style:none;
      display:flex;
      gap:1.4rem;
      margin:0;
      padding:0;
      font-size:0.9rem;
    }

    .nav a{
      text-decoration:none;
      color:var(--text-muted);
    }

    .nav a:hover{
      color:var(--text-heading);
    }

    main{
      max-width:var(--wrap);
      margin:0 auto;
      padding:var(--pad);
    }

    footer{
      border-top:1px solid var(--border-soft);
      margin-top:5rem;
    }

    footer .footer-inner{
      max-width:var(--wrap);
      margin:0 auto;
      padding:2.5rem var(--pad);
      font-size:0.85rem;
      color:var(--text-muted);
    }

    .brand{
      text-align:center;
      margin:2.2rem 0 2.4rem 0;
    }

    .brand img{
      max-width:520px;
      width:100%;
      height:auto;
      display:inline-block;
    }

    .content-frame{
      background:var(--bg-panel-soft);
      border-radius:var(--radius);
      padding:2.6rem 3rem 3.5rem;
    }

    @media (max-width: 700px){
      .content-frame{
        padding:2.2rem 1.6rem;
      }
    }

    #out, #out *:not(a){
      color:var(--text-main)!important;
      background:transparent!important;
    }

    h1{
      color:var(--text-heading);
      font-size:3rem;
      letter-spacing:0.04em;
      margin:0 0 1.1em -0.4rem;
    }

    h2{
      color:var(--text-heading);
      font-size:2rem;
      margin:3.4em 0 1em -0.4rem;
    }

    h3{
      color:var(--accent);
      font-size:1.05rem;
      letter-spacing:0.16em;
      text-transform:uppercase;
      margin:2.6em 0 0.8em -0.4rem;
    }
#out h3 em{
  color: #ffffff !important;
}
    p{
      margin:1.1em 0;
      max-width:70ch;
    }

  #out > h3:first-of-type,
  #out > p:first-of-type {
  text-align: center;
  margin-left: auto;
  margin-right: auto;
}
    ul{
      margin:1em 0 1.6em 1.4em;
      max-width:70ch;
    }

    li{
      margin:0.55em 0;
    }

    hr{
      border:none;
      border-top:1px solid var(--border-soft);
      margin:4em 0;
    }

/* Tighten spacing for Markdown section separators */
#out hr{
  margin: 1.2rem 0;
}   
    .muted{
      color:var(--text-muted);
    }

    @media (prefers-reduced-motion: reduce){
      *{
        animation:none!important;
        transition:none!important;
      }
    }
  </style>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/dompurify@3.1.6/dist/purify.min.js"></script>
</head>

<body>
  <a href="#main" class="skip-link">Skip to content</a>

<header>
  <nav class="nav" aria-label="Primary">
    <div class="brand-text">COMPAiSS</div>
    <ul>
      <li><a href="#" aria-disabled="true">AI Governance</a></li>
      <li><a href="/index_french.html">FR</a></li>
    </ul>
  </nav>
</header>

  <main id="main">
    <div class="brand">
      <img
        src="/assets/compaiss-logo-v2.png"
        alt="COMPAiSS - Guided by Deep Knowledge"
      >
    </div>

    <div class="content-frame">
      <div id="out"></div>
    </div>
  </main>

<footer>
  <div class="footer-inner">
    <p class="muted" style="margin-top: 0.8rem;">
      Contact:
      <a href="mailto:counterfactualtheory@gmail.com">
        counterfactualtheory@gmail.com
      </a>
    </p>
  </div>
</footer>

  <script>
    marked.setOptions({
      gfm:true,
      breaks:true,
      mangle:false,
      headerIds:false
    });

    const outEl = document.getElementById('out');

    function safeRender(md){
      const html = marked.parse(md || '');
      const clean = DOMPurify.sanitize(html, { ADD_ATTR: ['target','rel'] });
      outEl.innerHTML = clean;
      outEl.querySelectorAll('a').forEach(a=>{
        a.target='_blank';
        a.rel='noopener';
      });
    }

    const LANDING_MD = `
### An AI system engineered to prevent unauthorized institutional hallucinations by design

**Where AI stops guessing.**

---

## What COMPAiSS Does

Websites for regulated institutions contain thousands of pages of information - policies, procedures, rules, and support resources - typically distributed across multiple departments, administrative offices, and service units. For most users, navigating these opaque websites to find the right answer quickly is a daunting proposition.

Universities are a clear example of this challenge.

A university’s web ecosystem spans academic policies, program requirements, admissions rules, financial regulations, accessibility services, immigration guidance, housing, health services, and student rights - each governed by different offices and updated on different schedules.

Students trying to understand how a university actually works often begin in the same place: the university website.

A domestic student may be looking for clarity on academic standing, accommodations, course requirements, transfer credits, student loans, or financial policies. An international student may be trying to understand student visa regulations, work eligibility, health coverage, or immigration-related rules. Prospective students may be comparing programs, admissions criteria, deadlines, or available supports.

In all cases, the information usually exists - but it is spread across hundreds or thousands of webpages and policy documents.

COMPAiSS solves this problem for universities and other highly regulated institutions (such as hospitals and government service departments) that have an obligation to provide clear, accurate, and authoritative information, all delivered *in any language* the user prefers.

---

## The Structural Problem with AI Systems Today

As a direct consequence of complex institutional web ecosystems, many users turn to consumer-based AI systems (ChatGPT, Copilot, Gemini, and similar tools) to obtain fast, clear answers to institution-specific questions.

But consumer AI models are designed to generate responses by default. They optimize for broad usefulness across a vast training base that can reasonably be described as a universe of knowledge. When these systems are applied to narrow, institution-specific questions, errors, hallucinations, and references to non-authoritative or external sources are a predictable byproduct of that design.

The AI industry readily acknowledges these facts - incorrect or unsupported answers are generally treated as expected outcomes to be managed rather than failures to be prevented. This trade-off is widely accepted as the cost of maintaining broad, open-ended access to general knowledge.

In practice, most users do not have the time, expertise, or institutional context to independently verify AI-generated answers - even when warnings or disclaimers are provided. As a result, inaccurate information is often acted upon before it is questioned, amplifying downstream risk rather than containing it.

There are also strong economic incentives to preserve this generation-first model. Managing risk after answers are produced enables entire ecosystems of enterprise features - monitoring tools, compliance dashboards, moderation layers, human review workflows, and governance add-ons - that are costly to build, costly to operate, and highly profitable to sell. 

In regulated institutional environments, however, this approach introduces risks that are difficult - if not impossible - to fully mitigate after an answer has already been delivered. To compensate, vendors typically recommend layering additional controls and liability protections on top of generative systems, such as disclaimers and legal compliance frameworks.

These measures (assuming an institution can afford them) may reduce exposure, but they do not change the underlying generation-first architecture or eliminate the root causes of hallucinations. They still happen.

➡️ **[View Empirical Hallucination Rates Across Leading AI Models (2023–2025) (PDF)](/assets/hallucination_rates_in_contemporary_ai_Systems-2023-2025.pdf)**

In regulated institutional environments, this leaves a fundamental gap - one that COMPAiSS is designed to address by introducing an architectural innovation that prevents unsupported answers from being generated in the first place.

---

## COMPAiSS: The Structural Solution to Systemic AI Failure

Instead of generating an answer by default and attempting to manage risk afterward, COMPAiSS evaluates each question for institutional authorization before primary model inference is permitted to occur.

When a question is asked, the system first determines:

- whether the question falls within an institution’s defined scope
- whether authoritative, institution-approved material exists to support an answer
- and whether producing an answer would be responsible and defensible

The AI model is only allowed to provide an answer when those conditions are met.

This means COMPAiSS does not rely on disclaimers, confidence scores, post-answer filtering, or human review to retrofit compliance after an answer has already been produced. Unsupported or out-of-scope questions are prevented from triggering primary institutional model execution in the first place.

This pre-generation gating alone eliminates a significant class of errors common to consumer AI systems, where answers appear plausible and well-linked but are drawn from non-authoritative or external sources that only seem institutionally relevant.

When a question is clearly institution-specific and authoritative information exists within approved sources, COMPAiSS produces a clear answer grounded exclusively in that institution’s authorized materials - not inferred from the broader universe of unrelated organizations or jurisdictions. When a question cannot be supported, the system does not guess, generalize, fill gaps, or improvise simply to be "helpful".

By shifting decision-making ahead of AI generation, COMPAiSS removes the need for many of the costly corrective controls required by generation-first AI systems and eliminating a major class of unauthorized institutional hallucinations by design.

---

## Why COMPAiSS Is Not a General-Purpose AI System

The differences described above are not merely implementation choices - they reflect a fundamentally different design goal. 

General-purpose AI systems are designed to answer questions about anything. Their value lies in breadth: the ability to move freely across domains, institutions, jurisdictions, and topics by inferring context from a vast and continually expanding training corpus - without any predefined institutional or authoritative boundaries in place **before** an initial answer is generated.

COMPAiSS is not built for breadth; it is intentionally built for institutional specificity. This alone removes errors and risks by operating inside a single, well-defined organizational context, where authority, responsibility, and accountability matter more than coverage - particularly in regulated or policy-bound environments.

Its purpose is not to approximate an answer from general knowledge, but to reflect **only** what a particular institution has actually authorized as its official position, policy, or guidance, and **only** then release the AI to answer the question. This makes COMPAiSS more suitable for environments where answers must be traceable, defensible, and consistent over time and across audiences.

In short, general-purpose AI optimizes for how much it can answer.

COMPAiSS optimizes for when it is appropriate to provide answers about your institution, based on your information - and when it is not.

---

## Why COMPAiSS Is Not a FAQ Bot or Scripted Chatbot

FAQ systems are built around predefined questions and fixed answers, requiring users to frame their questions within those limits.

They break down when questions exceed those limits or require context, judgment, or interpretation of institutional rules and responsibilities.

COMPAiSS does not rely on scripts. Each question is evaluated on its own terms, drawing from relevant institutional information to provide clear, detailed, and nuanced answers aligned with what users are actually seeking.

---

## Why COMPAiSS Is Not Retrieval-Augmented Generation (RAG)

RAG systems connect AI to an institution’s documents or databases so it can “look things up” while generating an answer.

Many AI systems rely on RAG and similar post-processing controls to reduce hallucinations after a response has already been generated.

These approaches often require additional layers of infrastructure - including retrieval pipelines, vector databases, monitoring systems, validation tools, and ongoing oversight. These components increase complexity and cost, and are typically bundled into expensive enterprise contracts.

By contrast, COMPAiSS operates earlier.

By preventing unsupported or unanswerable questions from triggering the AI model in the first place, COMPAiSS prevents unsupported responses from being generated at all, materially reducing reliance on costly post-generation cleanup tools and systems. Accuracy and authority are established before any answer is produced, reducing both operational risk and the costs associated with correcting errors.

This difference is not a tuning choice or configuration detail - it reflects a fundamentally different architectural approach.

---

### Figure 1 — Standard Generation-First AI / RAG Architecture

This diagram illustrates how conventional AI and RAG systems operate with **model inference active from the start**, relying on retrieval and post-generation controls to manage risk after an answer has already been produced.

➡️ **[View Standard RAG Architecture - Figure 1 (PDF)](/assets/rag_figure_1.pdf)**

---

### Figure 2 — COMPAiSS Execution-Gated Architecture

This diagram shows COMPAiSS’s execution-gated design, where **authorization and scope validation occur before any model inference**, and unsupported questions prevent the AI from running at all.

➡️ **[View COMPAiSS Architecture - Figure 2 (PDF)](/assets/compaiss_figure_2.pdf)**

---

## COMPAiSS Architecture

At its core, COMPAiSS is built on an *execution-gated inference* architecture - in essence, the AI will not answer questions it is not authorized to answer.

If authorization fails, the primary institutional reasoning model does not execute or allocate primary inference resources.

By controlling whether AI reasoning happens at all, COMPAiSS enforces institutional authority structurally, rather than relying on post-generation filtering or correction.

COMPAiSS employs defense-in-depth controls: authorization gating prevents unauthorized primary model execution, instruction-based constraints guide behavior during authorized inference, and post-generation validation ensures URL compliance with institutional sources.

➡️ **[View Comparison Table (PDF)](/assets/compaiss_vs_rag_tables_1_2-v2.pdf)**

---

**These architectural differences are what allow COMPAiSS to operate safely in regulated environments where accuracy is non-negotiable.**

![COMPAiSS Executive Comparison](/assets/compaiss_executive_comparison.png)

---

For readers evaluating the financial implications of retrieval-augmented generation (RAG) versus execution-gated architecture, the following tables provide a structured comparison of core AI operating costs only — specifically token inference usage, infrastructure, and governance overhead directly associated with model operation.

These figures do not represent total institutional AI program costs. Rather, they isolate the compute-layer and architecture-layer expenses that materially differ between conventional RAG systems and execution-gated systems such as COMPAiSS.

Enterprise licensing, procurement terms, integration services, internal staffing, change management, and institution-specific contractual arrangements are outside the scope of these tables and vary by deployment size and environment.

➡️ **[Cost Savings by Design - Comparative Cost Analysis (PDF)](/assets/cost_savings_by_design.pdf)**

---

## Keeping Meaning Consistent Across Translations: COMPAiSS vs. RAG

Consumer-based AI systems often translate a user’s question (typically into English) as part of how they search for information, and then translate the answer back into the user’s language. In many RAG-based systems, this translation step is intertwined with retrieval and reasoning. As a result, small differences in phrasing can influence which documents are retrieved, how passages are interpreted, and what the system ultimately emphasizes in its response. 

Over time, this can lead to inconsistent answers across languages - even when the same question is asked and the same documents are informing the response.

COMPAiSS is designed to avoid this problem by separating language from meaning at the architectural level.

When a question is submitted in a non-English language, it is first translated into English using GPT-4o-mini, a high-accuracy translation model. This step exists solely to normalize the question into a single working language and operates as a preprocessing layer outside the institutional authorization framework. It does not retrieve documents, interpret policy, apply institutional rules, or generate answers.

Once translated, the question is evaluated for institutional scope and authorization before any primary institutional reasoning occurs. Only if authoritative, institution-approved sources are confirmed does the primary AI model - ChatGPT-5.2-latest - generate an answer, drawing exclusively from those authorized materials.

After the answer is determined, it is translated back into the user’s chosen language for presentation.

This separation is deliberate. Translation is treated strictly as a linguistic operation, not a discovery, retrieval, or reasoning step. As a result, changing the language does not change what information is considered relevant, which institutional materials are used, or how the answer is determined - only how it is expressed.

By fixing meaning, scope, and authorization before generation occurs, COMPAiSS prevents the interpretive drift and cross-language inconsistency common in RAG-based systems, ensuring that institutional answers remain accurate, authoritative, and consistent regardless of language.

---

## Where Accuracy Is Not Optional

The consequences of incorrect information vary by context. In the highly regulated environments below, they are not theoretical.

### *Universities*

Universities publish policies governing admissions, academic standing, accommodations, financial aid, degree requirements, and student rights.

An incorrect answer can:
- Misrepresent official policy  
- Lead to improper decisions or appeals  
- Create equity and compliance issues  

COMPAiSS ensures that answers reflect what the institution actually authorizes, not what an AI model infers.

---

### *Hospitals and Health Care Systems*

Hospitals operate under strict clinical, administrative, and regulatory constraints.

Inaccurate information can:
- Misstate patient rights or procedures  
- Create compliance exposure  
- Undermine trust in care delivery  

COMPAiSS limits answers to what the organization can verify and support, preventing speculative or generalized responses.

---

### *Government and Public-Facing Services*

Public agencies provide information that affects benefits, eligibility, obligations, and access to services.

Incorrect guidance can:
- Delay or deny services  
- Create legal exposure  
- Erode public trust  

COMPAiSS ensures that AI-mediated answers remain aligned with official rules, policies, and mandates.

---

### *Professional Regulatory Bodies*

Regulatory organizations publish licensing requirements, disciplinary procedures, eligibility criteria, and professional standards.

Inaccurate guidance can:
- Misrepresent statutory requirements
- Expose the organization to legal challenge
- Create direct professional harm

COMPAiSS prevents interpretive AI responses in areas where licensing, compliance, or discipline are governed by formally published rules. If an answer is not authorized by the organization’s materials, inference does not occur.

---

### *Colleges and Polytechnics*

Colleges publish structured program requirements, credential pathways, and admissions standards.

Incorrect information can:
- Mislead prospective students
- Trigger formal complaints or appeals
- Create reputational damage in competitive enrollment environments

COMPAiSS ensures that student-facing AI reflects official academic calendars and policy documents without extrapolating beyond institutional intent.

---

### *Municipal Governments*

Municipalities publish permit procedures, zoning regulations, licensing rules, and service eligibility criteria.

Incorrect guidance can:
- Create legal liability
- Delay projects or public services
- Generate political accountability issues

COMPAiSS prevents AI from fabricating procedural guidance in areas governed by published bylaws and formal regulations.

---

## Institutional Accountability and Control

Beyond preventing AI-generated errors, COMPAiSS has direct implications for institutional accountability and content governance. When institutions provide information, they implicitly promise that it is:

- Accurate
- Authoritative
- Reliable

COMPAiSS extends that same standard into AI-mediated answers by ensuring that primary institutional responses are grounded in institution-approved sources. It does not attempt to approximate institutional intent or fill gaps with generalized knowledge.

Of course, it is important to note that COMPAiSS, like any information system, reflects the authoritative materials it is permitted to use. If an authorized institutional link, webpage, policy document, or official guidance is outdated or requires revision, that limitation applies equally to any AI system, search tool, or human process relying on the same source. COMPAiSS does not reinterpret or supplement institutional content; it reflects what the institution itself has authorized.

The difference lies in visibility and control. By restricting answers to institution-approved sources and preventing unsupported inference, COMPAiSS makes gaps or inconsistencies explicit and correctable rather than obscuring them through generalized or speculative responses. This allows institutions to identify and correct content issues at the source, instead of unknowingly propagating inaccuracies through consumer AI systems operating outside institutional oversight.

---

**Regulated institutions deserve AI systems that respect their obligations - not ones that bypass them to be "helpful".**  

**COMPAiSS is designed for institutional environments where accuracy, authority, and governance are non-negotiable.**

---

## Technical Documentation and Further Reading

For institutions evaluating the governance implications of AI in regulated environments, the following brief paper outlines the structural argument behind COMPAiSS and the limitations of generation-first systems.

**[Authorization-Controlled Institutional AI in Regulated Environments](/assets/compaiss_institutional_positioning.pdf)**


For a deeper, non-technical overview of this approach, the following brief paper expands on the structural arguments behind COMPAiSS and the limitations and associated costs of post-generation controls in regulated environments.

**[The Road Less Travelled - Rethinking Generative AI Costs, Safety, and Trust in Regulated Institutions](/assets/compaiss-the_road_less_travelled.pdf)**


The next report presents a structured, cross-model consensus analysis of how leading AI consulting firms conceptualize hallucinations and where they assume control can occur within the AI lifecycle.

**[Hallucinations by Design - A Cross-Model Assessment of How Major AI Consulting Firms Advise Clients to Manage Generative AI Errors](/assets/final_report-hallucinations_by_design-v2.pdf)**

---

## Explore This Architecture

COMPAiSS is currently deployed in pilot programs at Canadian research universities, validating execution-gated inference in production institutional environments.

**For institutional evaluation or technology partnership inquiries:**

**Contact:** counterfactualtheory@gmail.com 

We welcome inquiries from:
- Institutions interested in testing COMPAiSS for their AI assistant deployments
- Technology vendors exploring execution-gated architecture for their product roadmaps
- Research groups investigating architectural approaches to AI safety and governance

---

## About COMPAiSS

COMPAiSS was developed to address a structural challenge in institutional AI deployment: how to provide AI-assisted information access in regulated environments where accuracy is legally and ethically non-negotiable.

The architecture emerged from extensive research into authorization-controlled inference and has been validated through pilot deployments at Canadian research universities serving diverse, multilingual student populations.

### Development

COMPAiSS represents a multi-year research and development effort focused on execution-gated inference architecture. The system was designed, built, and refined through thousands of hours of architectural design, policy mapping, prompt engineering, and validation testing across real institutional use cases.

Development included:
- Logic architecture and authorization framework design
- Compliance pathway structuring for regulated environments
- Performance benchmarking and iterative refinement
- Validation through targeted test scenarios across student, faculty, and administrative contexts
- Backend engineering (Node.js, API integration, deployment infrastructure)

### Leadership

**System Architecture & Development**  
Led by a senior academic leader with three decades of experience in university governance, including roles as President, Provost, Vice-President Academic, Dean, and Department Chair. This institutional perspective informed COMPAiSS's design principles around authority, accountability, and governance control.

**Institutional Engagement**  
Strategic outreach and partnership development coordinated through experienced advisors specializing in higher education stakeholder engagement, institutional positioning, and senior leadership consultation.

**Technical Infrastructure**  
Backend engineering and platform development supported by specialists in JavaScript/Node.js development, API integration, deployment systems, and prompt optimization.

### Research Foundation

COMPAiSS architecture is grounded in:
- Institutional governance frameworks for AI deployment
- Authorization-control mechanisms in regulated environments
- Structural approaches to hallucination prevention
- Multilingual response consistency across translation layers

Current pilot deployments continue to inform architectural refinement and validate execution-gated inference in production institutional contexts.
    `;

    safeRender(LANDING_MD);
  </script>
</body>
</html>
